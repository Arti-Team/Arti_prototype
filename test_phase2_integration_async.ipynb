{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Art Curation Integration Test (Async Fixed)\n",
    "\n",
    "async/await 문제를 해결한 버전입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 환경 설정 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/ijunhyeong/Desktop/arti_llm/studio')\n",
    "\n",
    "# 환경 변수 설정\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"✅ 환경 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/arti_chatbot/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/arti_chatbot/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 그래프 로드 성공\n",
      "그래프 노드들: ['__start__', 'conversation_node', 'art_curation_node', '__end__']\n"
     ]
    }
   ],
   "source": [
    "# 그래프 로드 테스트\n",
    "from emotional_art_graph import graph, EmotionalArtState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"✅ 그래프 로드 성공\")\n",
    "print(f\"그래프 노드들: {list(graph.get_graph().nodes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 그래프 구조 ===\n",
      "노드들: ['__start__', 'conversation_node', 'art_curation_node', '__end__']\n",
      "엣지들: [Edge(source='__start__', target='conversation_node', data=None, conditional=False), Edge(source='conversation_node', target='__end__', data=None, conditional=True), Edge(source='conversation_node', target='art_curation_node', data=None, conditional=True), Edge(source='art_curation_node', target='__end__', data=None, conditional=False)]\n",
      "\n",
      "=== Mermaid 다이어그램 ===\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tconversation_node(conversation_node)\n",
      "\tart_curation_node(art_curation_node)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> conversation_node;\n",
      "\tconversation_node -.-> __end__;\n",
      "\tconversation_node -.-> art_curation_node;\n",
      "\tart_curation_node --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그래프 구조 확인\n",
    "graph_info = graph.get_graph()\n",
    "print(\"=== 그래프 구조 ===\")\n",
    "print(f\"노드들: {list(graph_info.nodes.keys())}\")\n",
    "print(f\"엣지들: {graph_info.edges}\")\n",
    "\n",
    "# Mermaid 다이어그램 출력\n",
    "try:\n",
    "    mermaid_code = graph.get_graph().draw_mermaid()\n",
    "    print(\"\\n=== Mermaid 다이어그램 ===\")\n",
    "    print(mermaid_code)\n",
    "except Exception as e:\n",
    "    print(f\"그래프 시각화 실패: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== should_curate_art 함수 직접 테스트 ===\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "테스트 1: {'current_phase': 'greeting', 'consent_for_reco': False} -> __end__\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: False\n",
      "테스트 2: {'current_phase': 'ready_for_curation', 'consent_for_reco': False} -> art_curation_node\n",
      "DEBUG: Routing to art curation - phase: deep_sensing, consent: True\n",
      "테스트 3: {'current_phase': 'deep_sensing', 'consent_for_reco': True} -> art_curation_node\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "테스트 4: {'current_phase': 'ready_for_curation', 'consent_for_reco': True} -> art_curation_node\n"
     ]
    }
   ],
   "source": [
    "# should_curate_art 함수 직접 테스트\n",
    "from emotional_art_graph import should_curate_art\n",
    "\n",
    "print(\"=== should_curate_art 함수 직접 테스트 ===\")\n",
    "\n",
    "test_cases = [\n",
    "    {\"current_phase\": \"greeting\", \"consent_for_reco\": False},\n",
    "    {\"current_phase\": \"ready_for_curation\", \"consent_for_reco\": False},\n",
    "    {\"current_phase\": \"deep_sensing\", \"consent_for_reco\": True},\n",
    "    {\"current_phase\": \"ready_for_curation\", \"consent_for_reco\": True},\n",
    "]\n",
    "\n",
    "for i, test_state in enumerate(test_cases):\n",
    "    result = should_curate_art(test_state)\n",
    "    print(f\"테스트 {i+1}: {test_state} -> {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 그래프 다시 로드됨\n"
     ]
    }
   ],
   "source": [
    "# 모듈 강제 reload\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "if 'emotional_art_graph' in sys.modules:\n",
    "    importlib.reload(sys.modules['emotional_art_graph'])\n",
    "\n",
    "from emotional_art_graph import graph\n",
    "print(\"✅ 그래프 다시 로드됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기본 대화 테스트 (ASYNC) ===\n",
      "실행 전 상태:\n",
      "- current_phase: greeting\n",
      "- consent_for_reco: False\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "예상 라우팅: __end__\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=Hello, I'm feeling stressed from work.\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Final merged hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['stressed']) or situation hints (['work stress']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: []\n",
      "DEBUG: Current situation hints in state: []\n",
      "DEBUG: Final emotion hints: ['stressed']\n",
      "DEBUG: Final situation hints: ['work stress']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"Hello, I'm feeling stressed from work.\"]\n",
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "\n",
      "✅ 실행 성공!\n",
      "마지막 메시지: Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your d...\n",
      "현재 단계: greeting\n",
      "감정 힌트: ['stressed']\n",
      "상황 힌트: ['work stress']\n"
     ]
    }
   ],
   "source": [
    "# 기본 대화 테스트 (ASYNC 사용)\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"test_user_123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hello, I'm feeling stressed from work.\")],\n",
    "    \"emotion_hints\": [],\n",
    "    \"situation_hints\": [],\n",
    "    \"current_phase\": \"greeting\"\n",
    "}\n",
    "\n",
    "print(\"=== 기본 대화 테스트 (ASYNC) ===\")\n",
    "print(\"실행 전 상태:\")\n",
    "print(f\"- current_phase: {initial_state.get('current_phase')}\")\n",
    "print(f\"- consent_for_reco: {initial_state.get('consent_for_reco', False)}\")\n",
    "\n",
    "# should_curate_art로 라우팅 확인\n",
    "routing_result = should_curate_art(initial_state)\n",
    "print(f\"예상 라우팅: {routing_result}\")\n",
    "\n",
    "try:\n",
    "    # ASYNC 호출 사용\n",
    "    result = await graph.ainvoke(initial_state, config=config)\n",
    "    print(f\"\\n✅ 실행 성공!\")\n",
    "    print(f\"마지막 메시지: {result['messages'][-1].content[:100]}...\")\n",
    "    print(f\"현재 단계: {result.get('current_phase', 'Unknown')}\")\n",
    "    print(f\"감정 힌트: {result.get('emotion_hints', [])}\")\n",
    "    print(f\"상황 힌트: {result.get('situation_hints', [])}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 기본 대화 테스트 실패: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 스트리밍으로 노드 실행 과정 확인 (ASYNC) ===\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=Hello, I'm feeling stressed from work.\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Final merged hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['stressed']) or situation hints (['work stress']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: []\n",
      "DEBUG: Current situation hints in state: []\n",
      "DEBUG: Final emotion hints: ['stressed']\n",
      "DEBUG: Final situation hints: ['work stress']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"Hello, I'm feeling stressed from work.\"]\n",
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "스텝: {'conversation_node': {'messages': [AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='1542d2c0-9eae-4236-be62-ff3f8ede709c')], 'emotion_hints': ['stressed'], 'situation_hints': ['work stress']}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍으로 각 노드 실행 과정 확인 (ASYNC)\n",
    "print(\"=== 스트리밍으로 노드 실행 과정 확인 (ASYNC) ===\")\n",
    "\n",
    "stream_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hello, I'm feeling stressed from work.\")],\n",
    "    \"emotion_hints\": [],\n",
    "    \"situation_hints\": [],\n",
    "    \"current_phase\": \"greeting\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # ASYNC 스트리밍 사용\n",
    "    async for step in graph.astream(stream_state, config=config):\n",
    "        print(f\"스텝: {step}\")\n",
    "        print(\"---\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 스트리밍 테스트 실패: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Art Curation 트리거 조건 테스트 (ASYNC) ===\n",
      "큐레이션 준비 상태:\n",
      "- current_phase: ready_for_curation\n",
      "- consent_for_reco: True\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "예상 라우팅: art_curation_node\n",
      "\n",
      "큐레이션 준비 상태로 스트리밍 테스트...\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints', 'consent_for_reco']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=I'm really stressed and overwhelmed. Can you recommend some art for me?\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed', 'overwhelmed'], situations: []\n",
      "DEBUG: Final merged hints - emotions: ['stressed', 'overwhelmed', 'anxious'], situations: ['work pressure', 'academic stress']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['stressed', 'overwhelmed', 'anxious']) or situation hints (['work pressure', 'academic stress']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: ['stressed', 'overwhelmed', 'anxious']\n",
      "DEBUG: Current situation hints in state: ['work pressure', 'academic stress']\n",
      "DEBUG: Final emotion hints: ['stressed', 'overwhelmed', 'anxious']\n",
      "DEBUG: Final situation hints: ['work pressure', 'academic stress']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"I'm really stressed and overwhelmed. Can you recommend some art for me?\"]\n",
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "스텝: {'conversation_node': {'messages': [AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='2932066d-322d-4245-9a96-63721d2d216b')], 'emotion_hints': ['stressed', 'overwhelmed', 'anxious'], 'situation_hints': ['work pressure', 'academic stress']}}\n",
      "---\n",
      "WARNING: Store is None in art_curation_node, using InMemoryStore fallback\n",
      "DEBUG: Starting art curation node\n",
      "DEBUG: Loaded user memories: []\n",
      "DEBUG: conversation_state type: <class 'dict'>\n",
      "DEBUG: conversation_state content: {'messages': [HumanMessage(content=\"I'm really stressed and overwhelmed. Can you recommend some art for me?\", additional_kwargs={}, response_metadata={}, id='911c4d13-5ed0-40d8-94ce-d9515a512889'), AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='2932066d-322d-4245-9a96-63721d2d216b')], 'current_phase': 'ready_for_curation', 'emotion_hints': ['stressed', 'overwhelmed', 'anxious'], 'situation_hints': ['work pressure', 'academic stress'], 'consent_for_reco': True}\n",
      "DEBUG: Curation input prepared: {'situation': 'general emotional support and mood enhancement', 'emotions': ['stressed', 'overwhelmed', 'anxious'], 'preferences': None, 'confidence_level': 0.6000000000000001}\n",
      "DEBUG: Changed to art curation directory: /Users/ijunhyeong/Desktop/arti_llm/art_curation_engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:Setting up LangChain RAG components...\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading LangChain RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:✅ Embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:art_curation_engine.core.langchain_rag_system:✅ Text splitter configured\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:art_curation_engine.core.langchain_rag_system:✅ Vector store loaded from langchain_vectorstore\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store\n",
      "✅ LangChain RAG system loaded successfully\n",
      "✅ LLM setup complete (OpenAI)\n",
      "📚 Extracting subject vocabulary from metadata...\n",
      "✅ Extracted 353 unique subject terms\n",
      "📊 Top 10 subjects: [('portraits', 261), ('portrait', 197), ('portraits: male subject', 103), ('man', 88), ('fashion', 85), ('portraits: female subject', 85), ('people', 76), ('woman', 63), ('century of progress', 60), (\"world's fairs\", 60)]\n",
      "✅ Loaded 10 concept categories\n",
      "✅ LLM setup complete for dynamic generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x34b14a350>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x34b14bd90>\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:LLM initialized successfully\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 60 cached scores\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 30 cached justifications\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Step 6 LLM Reranker initialized with model: accounts/fireworks/models/llama-v3p1-70b-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Could not load similarity model: PermissionError at /Volumes/X31 when downloading sentence-transformers/all-MiniLM-L6-v2. Check cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); 2) a previous download was canceled and the lock file needs manual removal.\n",
      "✅ Dynamic Keyword/Prompt Generator initialized\n",
      "✅ Dynamic keyword/prompt generator initialized\n",
      "📚 Loaded 298 artworks from metadata\n",
      "✅ Stage A initialized with 298 artworks\n",
      "DEBUG: Starting Step 5 - RAG brief generation\n",
      "DEBUG: Starting Stage A - Candidate collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Generating session brief with dynamic LangChain RAG...\n",
      "   Situation: general emotional support and mood enhancement\n",
      "   Emotions: ['stressed', 'overwhelmed', 'anxious']\n",
      "✅ Using cached result\n",
      "\n",
      "🎭 Stage A: Candidate Collection (balanced mode)\n",
      "📝 Situation: general emotional support and mood enhancement\n",
      "😊 Emotions: ['stressed', 'overwhelmed', 'anxious']\n",
      "================================================================================\n",
      "🔍 A1: Metadata OR expansion (target: 200 candidates)\n",
      "🎯 Dynamic keyword/prompt generation...\n",
      "   Situation: general emotional support and mood enhancement...\n",
      "   Emotions: ['stressed', 'overwhelmed', 'anxious']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
      "INFO:root:Loaded built-in ViT-B-32 model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dynamic generation complete in 4.144s\n",
      "   Keywords: 10\n",
      "   Prompts: 3\n",
      "🔑 Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "✅ A1 complete: 200 candidates (from 294 matches)\n",
      "🎯 A2: CLIP text→image search (per_query: 140, cap: 150)\n",
      "🔧 Loading CLIP model and FAISS index...\n",
      "= Attempting to load model from local cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Instantiating model architecture: CLIP\n",
      "INFO:root:Loading full pretrained weights from: /Users/ijunhyeong/.cache/huggingface/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/snapshots/1a25a446712ba5ee05982a381eed697ef9b435cf/open_clip_model.safetensors\n",
      "INFO:root:Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
      "INFO:root:Model ViT-B-32 creation process complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully from local cache\n",
      "✅ FAISS index loaded with 298 embeddings\n",
      "📦 Dynamic generation cache hit in 0.000s\n",
      "🎨 Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, with ...\n",
      "   3. An abstract representation of anxiety, using swirling blue a...\n",
      "   🔍 Searching prompt 1/3: A serene landscape with a girl sitting by a calm body of wat...\n",
      "   🔍 Searching prompt 2/3: A portrait of a family enjoying a sunny day in a park, with ...\n",
      "   🔍 Searching prompt 3/3: An abstract representation of anxiety, using swirling blue a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.step6_llm_reranking:Starting Step 6 reranking: 3 → 8 candidates\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Phase 1: Scoring candidates with LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/emotional_art_graph.py\", line 1511, in art_curation_node\n",
      "    final_recs = await loop.run_in_executor(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/arti_chatbot/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 259, in rerank_candidates\n",
      "    all_scores = self._score_all_candidates(rag_brief, candidates, brief_hash)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 306, in _score_all_candidates\n",
      "    artwork_id = candidate.get('artwork_id', candidate.get('id', ''))\n",
      "                 ^^^^^^^^^^^^^\n",
      "AttributeError: 'str' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ A2 complete: 150 candidates from 239 total matches\n",
      "🔗 Merging A1 and A2 results (target: 150)\n",
      "✅ Merge complete: 150 final candidates\n",
      "📦 Dynamic generation cache hit in 0.000s\n",
      "🔑 Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "📦 Dynamic generation cache hit in 0.000s\n",
      "🎨 Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, with ...\n",
      "   3. An abstract representation of anxiety, using swirling blue a...\n",
      "\n",
      "📊 Stage A Results (balanced):\n",
      "   Final candidates: 150\n",
      "   A1 metadata hits: 200\n",
      "   A2 CLIP hits: 150\n",
      "   Generated keywords: 10\n",
      "   CLIP prompts: 3\n",
      "\n",
      "🎯 Generating session brief with dynamic LangChain RAG...\n",
      "   Situation: general emotional support and mood enhancement\n",
      "   Emotions: ['overwhelmed', 'stressed', 'tired']\n",
      "✅ Using cached result\n",
      "\n",
      "🎭 Stage A: Candidate Collection (balanced mode)\n",
      "📝 Situation: general emotional support and mood enhancement\n",
      "😊 Emotions: ['overwhelmed', 'stressed', 'tired']\n",
      "================================================================================\n",
      "🔍 A1: Metadata OR expansion (target: 200 candidates)\n",
      "🎯 Dynamic keyword/prompt generation...\n",
      "   Situation: general emotional support and mood enhancement...\n",
      "   Emotions: ['overwhelmed', 'stressed', 'tired']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Starting Step 6 - LLM reranking\n",
      "DEBUG: Art curation error: 'str' object has no attribute 'get'\n",
      "DEBUG: Restored working directory to /Users/ijunhyeong/Desktop/arti_llm\n",
      "스텝: {'art_curation_node': {'messages': [AIMessage(content='I encountered an issue with the art database. Would you like to continue our conversation, and I can try the recommendations again later?', additional_kwargs={}, response_metadata={}, id='2cecc9d3-6f8d-442e-9f2c-a16c7fc9af32')], 'current_phase': 'continuing'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Art Curation 트리거 조건 테스트 (ASYNC)\n",
    "print(\"=== Art Curation 트리거 조건 테스트 (ASYNC) ===\")\n",
    "\n",
    "# ready_for_curation 상태로 설정\n",
    "curation_ready_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"I'm really stressed and overwhelmed. Can you recommend some art for me?\"),\n",
    "    ],\n",
    "    \"emotion_hints\": [\"stressed\", \"overwhelmed\", \"anxious\"],\n",
    "    \"situation_hints\": [\"work pressure\", \"academic stress\"],\n",
    "    \"current_phase\": \"ready_for_curation\",\n",
    "    \"consent_for_reco\": True\n",
    "}\n",
    "\n",
    "print(\"큐레이션 준비 상태:\")\n",
    "print(f\"- current_phase: {curation_ready_state.get('current_phase')}\")\n",
    "print(f\"- consent_for_reco: {curation_ready_state.get('consent_for_reco')}\")\n",
    "\n",
    "# should_curate_art로 라우팅 확인\n",
    "routing_result = should_curate_art(curation_ready_state)\n",
    "print(f\"예상 라우팅: {routing_result}\")\n",
    "\n",
    "print(\"\\n큐레이션 준비 상태로 스트리밍 테스트...\")\n",
    "try:\n",
    "    async for step in graph.astream(curation_ready_state, config=config):\n",
    "        print(f\"스텝: {step}\")\n",
    "        print(\"---\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 큐레이션 트리거 테스트 실패: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== prepare_curation_input 함수 테스트 ===\n",
      "DEBUG: conversation_state type: <class '__main__.FakeState'>\n",
      "DEBUG: conversation_state content: <__main__.FakeState object at 0x1745e0650>\n",
      "✅ 큐레이션 입력 생성 성공:\n",
      "- situation: academic stress from research work with underlying feeling overwhelmed\n",
      "- emotions: ['overwhelmed', 'stressed', 'tired', 'anxious']\n",
      "- preferences: {'liked_styles': ['minimalist', 'abstract'], 'avoided_themes': [], 'effective_colors': ['blue', 'green'], 'preferred_periods': []}\n",
      "- confidence_level: 1.0\n"
     ]
    }
   ],
   "source": [
    "# prepare_curation_input 함수 테스트\n",
    "from emotional_art_graph import prepare_curation_input\n",
    "\n",
    "print(\"=== prepare_curation_input 함수 테스트 ===\")\n",
    "\n",
    "# 가짜 메모리 데이터\n",
    "fake_memories = {\n",
    "    'user_profile': {\n",
    "        'current_situation': 'academic stress from research work',\n",
    "        'emotional_context': 'feeling overwhelmed',\n",
    "        'emotions': ['stressed', 'anxious', 'tired']\n",
    "    },\n",
    "    'art_preferences': {\n",
    "        'preferred_styles': ['minimalist', 'abstract'],\n",
    "        'effective_colors': ['blue', 'green']\n",
    "    }\n",
    "}\n",
    "\n",
    "# 가짜 state 데이터 (EmotionalArtState와 유사하게)\n",
    "class FakeState:\n",
    "    def __init__(self, data):\n",
    "        self.emotion_hints = data.get('emotion_hints', [])\n",
    "        self.situation_hints = data.get('situation_hints', [])\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "\n",
    "fake_state = FakeState({\n",
    "    'emotion_hints': ['overwhelmed', 'stressed', 'tired'],\n",
    "    'situation_hints': ['academic pressure', 'research deadlines']\n",
    "})\n",
    "\n",
    "try:\n",
    "    curation_input = prepare_curation_input(fake_memories, fake_state)\n",
    "    print(f\"✅ 큐레이션 입력 생성 성공:\")\n",
    "    print(f\"- situation: {curation_input.get('situation')}\")\n",
    "    print(f\"- emotions: {curation_input.get('emotions')}\")\n",
    "    print(f\"- preferences: {curation_input.get('preferences')}\")\n",
    "    print(f\"- confidence_level: {curation_input.get('confidence_level')}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ prepare_curation_input 테스트 실패: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:core.langchain_rag_system:Setting up LangChain RAG components...\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Art Curation Engine 직접 테스트 ===\n",
      "✅ 작업 디렉토리 변경: /Users/ijunhyeong/Desktop/arti_llm/art_curation_engine\n",
      "🔄 Loading LangChain RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:core.langchain_rag_system:✅ Embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:core.langchain_rag_system:✅ Text splitter configured\n",
      "INFO:core.langchain_rag_system:✅ Vector store loaded from langchain_vectorstore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store\n",
      "✅ LangChain RAG system loaded successfully\n",
      "✅ LLM setup complete (OpenAI)\n",
      "✅ RAGSessionBrief 로드 성공\n",
      "테스트 입력: situation='academic stress from research work', emotions=['overwhelmed', 'stressed', 'tired']\n",
      "\n",
      "🎯 Generating session brief with dynamic LangChain RAG...\n",
      "   Situation: academic stress from research work\n",
      "   Emotions: ['overwhelmed', 'stressed', 'tired']\n",
      "✅ Using cached result\n",
      "✅ RAG Brief 생성 성공: <class 'dict'>\n",
      "Brief keys: ['brief', 'evidence_used', 'queries_used', 'user_input', 'metadata']\n",
      "Brief 샘플:\n",
      "  brief: {'situation_analysis': 'The user is experiencing academic stress from research work, leading to feel...\n",
      "  evidence_used: [{'title': 'Color arousal and performance A comparis', 'year': 'Unknown', 'domain': 'Color Psycholog...\n",
      "  queries_used: ['color psychology effects on stress reduction in academic environments', 'environmental design stra...\n",
      "✅ 작업 디렉토리 복원: /Users/ijunhyeong/Desktop/arti_llm\n"
     ]
    }
   ],
   "source": [
    "# Art Curation Engine 직접 테스트\n",
    "print(\"=== Art Curation Engine 직접 테스트 ===\")\n",
    "\n",
    "# art_curation_engine 디렉토리로 변경\n",
    "import os\n",
    "original_cwd = os.getcwd()\n",
    "art_engine_path = '/Users/ijunhyeong/Desktop/arti_llm/art_curation_engine'\n",
    "\n",
    "if os.path.exists(art_engine_path):\n",
    "    os.chdir(art_engine_path)\n",
    "    print(f\"✅ 작업 디렉토리 변경: {art_engine_path}\")\n",
    "    \n",
    "    try:\n",
    "        from core import RAGSessionBrief\n",
    "        \n",
    "        rag_session = RAGSessionBrief()\n",
    "        print(\"✅ RAGSessionBrief 로드 성공\")\n",
    "        \n",
    "        # 간단한 테스트\n",
    "        test_situation = \"academic stress from research work\"\n",
    "        test_emotions = [\"overwhelmed\", \"stressed\", \"tired\"]\n",
    "        \n",
    "        print(f\"테스트 입력: situation='{test_situation}', emotions={test_emotions}\")\n",
    "        \n",
    "        brief = rag_session.generate_brief(test_situation, test_emotions)\n",
    "        print(f\"✅ RAG Brief 생성 성공: {type(brief)}\")\n",
    "        print(f\"Brief keys: {list(brief.keys()) if isinstance(brief, dict) else 'Not a dict'}\")\n",
    "        \n",
    "        if isinstance(brief, dict):\n",
    "            print(f\"Brief 샘플:\")\n",
    "            for key, value in list(brief.items())[:3]:  # 처음 3개만 출력\n",
    "                print(f\"  {key}: {str(value)[:100]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Art Curation Engine 테스트 실패: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        os.chdir(original_cwd)\n",
    "        print(f\"✅ 작업 디렉토리 복원: {original_cwd}\")\n",
    "else:\n",
    "    print(f\"❌ Art Curation Engine 경로 없음: {art_engine_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전체 통합 테스트 (ASYNC) ===\n",
      "아트 큐레이션 전체 파이프라인 테스트...\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints', 'consent_for_reco']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed', 'overwhelmed', 'tired'], situations: ['work stress', 'mental health', 'need for relaxation']\n",
      "DEBUG: Final merged hints - emotions: ['overwhelmed', 'stressed', 'tired'], situations: ['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['overwhelmed', 'stressed', 'tired']) or situation hints (['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: ['overwhelmed', 'stressed', 'tired']\n",
      "DEBUG: Current situation hints in state: ['research work', 'academic pressure']\n",
      "DEBUG: Final emotion hints: ['overwhelmed', 'stressed', 'tired']\n",
      "DEBUG: Final situation hints: ['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:Setting up LangChain RAG components...\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "WARNING: Store is None in art_curation_node, using InMemoryStore fallback\n",
      "DEBUG: Starting art curation node\n",
      "DEBUG: Loaded user memories: []\n",
      "DEBUG: conversation_state type: <class 'dict'>\n",
      "DEBUG: conversation_state content: {'messages': [HumanMessage(content=\"I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\", additional_kwargs={}, response_metadata={}, id='88c8132d-e9df-458c-8393-b15c2d3c4c4d'), AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='ca87ce68-fb9e-488a-aa92-2a480f9a1ad1')], 'current_phase': 'ready_for_curation', 'emotion_hints': ['overwhelmed', 'stressed', 'tired'], 'situation_hints': ['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation'], 'consent_for_reco': True}\n",
      "DEBUG: Curation input prepared: {'situation': 'general emotional support and mood enhancement', 'emotions': ['overwhelmed', 'stressed', 'tired'], 'preferences': None, 'confidence_level': 0.6000000000000001}\n",
      "DEBUG: Changed to art curation directory: /Users/ijunhyeong/Desktop/arti_llm/art_curation_engine\n",
      "🔄 Loading LangChain RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:✅ Embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:art_curation_engine.core.langchain_rag_system:✅ Text splitter configured\n",
      "INFO:art_curation_engine.core.langchain_rag_system:✅ Vector store loaded from langchain_vectorstore\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store\n",
      "✅ LangChain RAG system loaded successfully\n",
      "✅ LLM setup complete (OpenAI)\n",
      "📚 Extracting subject vocabulary from metadata...\n",
      "✅ Extracted 353 unique subject terms\n",
      "📊 Top 10 subjects: [('portraits', 261), ('portrait', 197), ('portraits: male subject', 103), ('man', 88), ('fashion', 85), ('portraits: female subject', 85), ('people', 76), ('woman', 63), ('century of progress', 60), (\"world's fairs\", 60)]\n",
      "✅ Loaded 10 concept categories\n",
      "✅ LLM setup complete for dynamic generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x321c61e50>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x321c63450>\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:LLM initialized successfully\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 60 cached scores\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 30 cached justifications\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Step 6 LLM Reranker initialized with model: accounts/fireworks/models/llama-v3p1-70b-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Could not load similarity model: PermissionError at /Volumes/X31 when downloading sentence-transformers/all-MiniLM-L6-v2. Check cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); 2) a previous download was canceled and the lock file needs manual removal.\n",
      "✅ Dynamic Keyword/Prompt Generator initialized\n",
      "✅ Dynamic keyword/prompt generator initialized\n",
      "📚 Loaded 298 artworks from metadata\n",
      "✅ Stage A initialized with 298 artworks\n",
      "DEBUG: Starting Step 5 - RAG brief generation\n",
      "DEBUG: Starting Stage A - Candidate collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
      "INFO:root:Loaded built-in ViT-B-32 model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dynamic generation complete in 3.681s\n",
      "   Keywords: 10\n",
      "   Prompts: 3\n",
      "🔑 Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "✅ A1 complete: 200 candidates (from 294 matches)\n",
      "🎯 A2: CLIP text→image search (per_query: 140, cap: 150)\n",
      "🔧 Loading CLIP model and FAISS index...\n",
      "= Attempting to load model from local cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Instantiating model architecture: CLIP\n",
      "INFO:root:Loading full pretrained weights from: /Users/ijunhyeong/.cache/huggingface/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/snapshots/1a25a446712ba5ee05982a381eed697ef9b435cf/open_clip_model.safetensors\n",
      "INFO:root:Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
      "INFO:root:Model ViT-B-32 creation process complete.\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Starting Step 6 reranking: 3 → 8 candidates\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Phase 1: Scoring candidates with LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/emotional_art_graph.py\", line 1511, in art_curation_node\n",
      "    final_recs = await loop.run_in_executor(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/arti_chatbot/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 259, in rerank_candidates\n",
      "    all_scores = self._score_all_candidates(rag_brief, candidates, brief_hash)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 306, in _score_all_candidates\n",
      "    artwork_id = candidate.get('artwork_id', candidate.get('id', ''))\n",
      "                 ^^^^^^^^^^^^^\n",
      "AttributeError: 'str' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully from local cache\n",
      "✅ FAISS index loaded with 298 embeddings\n",
      "📦 Dynamic generation cache hit in 0.000s\n",
      "🎨 Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, weari...\n",
      "   3. An abstract representation of tiredness, using swirling blue...\n",
      "   🔍 Searching prompt 1/3: A serene landscape with a girl sitting by a calm body of wat...\n",
      "   🔍 Searching prompt 2/3: A portrait of a family enjoying a sunny day in a park, weari...\n",
      "   🔍 Searching prompt 3/3: An abstract representation of tiredness, using swirling blue...\n",
      "✅ A2 complete: 150 candidates from 235 total matches\n",
      "🔗 Merging A1 and A2 results (target: 150)\n",
      "✅ Merge complete: 150 final candidates\n",
      "📦 Dynamic generation cache hit in 0.000s\n",
      "🔑 Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "📦 Dynamic generation cache hit in 0.000s\n",
      "🎨 Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, weari...\n",
      "   3. An abstract representation of tiredness, using swirling blue...\n",
      "\n",
      "📊 Stage A Results (balanced):\n",
      "   Final candidates: 150\n",
      "   A1 metadata hits: 200\n",
      "   A2 CLIP hits: 150\n",
      "   Generated keywords: 10\n",
      "   CLIP prompts: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Starting Step 6 - LLM reranking\n",
      "DEBUG: Art curation error: 'str' object has no attribute 'get'\n",
      "DEBUG: Restored working directory to /Users/ijunhyeong/Desktop/arti_llm\n",
      "✅ 전체 테스트 성공\n",
      "마지막 메시지: I encountered an issue with the art database. Would you like to continue our conversation, and I can try the recommendations again later?...\n",
      "현재 단계: continuing\n"
     ]
    }
   ],
   "source": [
    "# 전체 통합 테스트 - art_curation_node까지 실행 (ASYNC)\n",
    "print(\"=== 전체 통합 테스트 (ASYNC) ===\")\n",
    "\n",
    "# Art curation을 트리거하는 상태\n",
    "full_test_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\")\n",
    "    ],\n",
    "    \"emotion_hints\": [\"overwhelmed\", \"stressed\", \"tired\"],\n",
    "    \"situation_hints\": [\"research work\", \"academic pressure\"],\n",
    "    \"current_phase\": \"ready_for_curation\",\n",
    "    \"consent_for_reco\": True\n",
    "}\n",
    "\n",
    "print(\"아트 큐레이션 전체 파이프라인 테스트...\")\n",
    "try:\n",
    "    result = await graph.ainvoke(full_test_state, config=config)\n",
    "    print(f\"✅ 전체 테스트 성공\")\n",
    "    print(f\"마지막 메시지: {result['messages'][-1].content[:200]}...\")\n",
    "    print(f\"현재 단계: {result.get('current_phase', 'Unknown')}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 전체 테스트 실패: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arti_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
