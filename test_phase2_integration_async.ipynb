{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Art Curation Integration Test (Async Fixed)\n",
    "\n",
    "async/await ë¬¸ì œë¥¼ í•´ê²°í•œ ë²„ì „ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/ijunhyeong/Desktop/arti_llm/studio')\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/arti_chatbot/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/arti_chatbot/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê·¸ë˜í”„ ë¡œë“œ ì„±ê³µ\n",
      "ê·¸ë˜í”„ ë…¸ë“œë“¤: ['__start__', 'conversation_node', 'art_curation_node', '__end__']\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "from emotional_art_graph import graph, EmotionalArtState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ ë¡œë“œ ì„±ê³µ\")\n",
    "print(f\"ê·¸ë˜í”„ ë…¸ë“œë“¤: {list(graph.get_graph().nodes.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ê·¸ë˜í”„ êµ¬ì¡° ===\n",
      "ë…¸ë“œë“¤: ['__start__', 'conversation_node', 'art_curation_node', '__end__']\n",
      "ì—£ì§€ë“¤: [Edge(source='__start__', target='conversation_node', data=None, conditional=False), Edge(source='conversation_node', target='__end__', data=None, conditional=True), Edge(source='conversation_node', target='art_curation_node', data=None, conditional=True), Edge(source='art_curation_node', target='__end__', data=None, conditional=False)]\n",
      "\n",
      "=== Mermaid ë‹¤ì´ì–´ê·¸ë¨ ===\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tconversation_node(conversation_node)\n",
      "\tart_curation_node(art_curation_node)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> conversation_node;\n",
      "\tconversation_node -.-> __end__;\n",
      "\tconversation_node -.-> art_curation_node;\n",
      "\tart_curation_node --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ê·¸ë˜í”„ êµ¬ì¡° í™•ì¸\n",
    "graph_info = graph.get_graph()\n",
    "print(\"=== ê·¸ë˜í”„ êµ¬ì¡° ===\")\n",
    "print(f\"ë…¸ë“œë“¤: {list(graph_info.nodes.keys())}\")\n",
    "print(f\"ì—£ì§€ë“¤: {graph_info.edges}\")\n",
    "\n",
    "# Mermaid ë‹¤ì´ì–´ê·¸ë¨ ì¶œë ¥\n",
    "try:\n",
    "    mermaid_code = graph.get_graph().draw_mermaid()\n",
    "    print(\"\\n=== Mermaid ë‹¤ì´ì–´ê·¸ë¨ ===\")\n",
    "    print(mermaid_code)\n",
    "except Exception as e:\n",
    "    print(f\"ê·¸ë˜í”„ ì‹œê°í™” ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== should_curate_art í•¨ìˆ˜ ì§ì ‘ í…ŒìŠ¤íŠ¸ ===\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "í…ŒìŠ¤íŠ¸ 1: {'current_phase': 'greeting', 'consent_for_reco': False} -> __end__\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: False\n",
      "í…ŒìŠ¤íŠ¸ 2: {'current_phase': 'ready_for_curation', 'consent_for_reco': False} -> art_curation_node\n",
      "DEBUG: Routing to art curation - phase: deep_sensing, consent: True\n",
      "í…ŒìŠ¤íŠ¸ 3: {'current_phase': 'deep_sensing', 'consent_for_reco': True} -> art_curation_node\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "í…ŒìŠ¤íŠ¸ 4: {'current_phase': 'ready_for_curation', 'consent_for_reco': True} -> art_curation_node\n"
     ]
    }
   ],
   "source": [
    "# should_curate_art í•¨ìˆ˜ ì§ì ‘ í…ŒìŠ¤íŠ¸\n",
    "from emotional_art_graph import should_curate_art\n",
    "\n",
    "print(\"=== should_curate_art í•¨ìˆ˜ ì§ì ‘ í…ŒìŠ¤íŠ¸ ===\")\n",
    "\n",
    "test_cases = [\n",
    "    {\"current_phase\": \"greeting\", \"consent_for_reco\": False},\n",
    "    {\"current_phase\": \"ready_for_curation\", \"consent_for_reco\": False},\n",
    "    {\"current_phase\": \"deep_sensing\", \"consent_for_reco\": True},\n",
    "    {\"current_phase\": \"ready_for_curation\", \"consent_for_reco\": True},\n",
    "]\n",
    "\n",
    "for i, test_state in enumerate(test_cases):\n",
    "    result = should_curate_art(test_state)\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ {i+1}: {test_state} -> {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê·¸ë˜í”„ ë‹¤ì‹œ ë¡œë“œë¨\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë“ˆ ê°•ì œ reload\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "if 'emotional_art_graph' in sys.modules:\n",
    "    importlib.reload(sys.modules['emotional_art_graph'])\n",
    "\n",
    "from emotional_art_graph import graph\n",
    "print(\"âœ… ê·¸ë˜í”„ ë‹¤ì‹œ ë¡œë“œë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸ (ASYNC) ===\n",
      "ì‹¤í–‰ ì „ ìƒíƒœ:\n",
      "- current_phase: greeting\n",
      "- consent_for_reco: False\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "ì˜ˆìƒ ë¼ìš°íŒ…: __end__\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=Hello, I'm feeling stressed from work.\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Final merged hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['stressed']) or situation hints (['work stress']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: []\n",
      "DEBUG: Current situation hints in state: []\n",
      "DEBUG: Final emotion hints: ['stressed']\n",
      "DEBUG: Final situation hints: ['work stress']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"Hello, I'm feeling stressed from work.\"]\n",
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "\n",
      "âœ… ì‹¤í–‰ ì„±ê³µ!\n",
      "ë§ˆì§€ë§‰ ë©”ì‹œì§€: Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your d...\n",
      "í˜„ì¬ ë‹¨ê³„: greeting\n",
      "ê°ì • íŒíŠ¸: ['stressed']\n",
      "ìƒí™© íŒíŠ¸: ['work stress']\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸ (ASYNC ì‚¬ìš©)\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"test_user_123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hello, I'm feeling stressed from work.\")],\n",
    "    \"emotion_hints\": [],\n",
    "    \"situation_hints\": [],\n",
    "    \"current_phase\": \"greeting\"\n",
    "}\n",
    "\n",
    "print(\"=== ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸ (ASYNC) ===\")\n",
    "print(\"ì‹¤í–‰ ì „ ìƒíƒœ:\")\n",
    "print(f\"- current_phase: {initial_state.get('current_phase')}\")\n",
    "print(f\"- consent_for_reco: {initial_state.get('consent_for_reco', False)}\")\n",
    "\n",
    "# should_curate_artë¡œ ë¼ìš°íŒ… í™•ì¸\n",
    "routing_result = should_curate_art(initial_state)\n",
    "print(f\"ì˜ˆìƒ ë¼ìš°íŒ…: {routing_result}\")\n",
    "\n",
    "try:\n",
    "    # ASYNC í˜¸ì¶œ ì‚¬ìš©\n",
    "    result = await graph.ainvoke(initial_state, config=config)\n",
    "    print(f\"\\nâœ… ì‹¤í–‰ ì„±ê³µ!\")\n",
    "    print(f\"ë§ˆì§€ë§‰ ë©”ì‹œì§€: {result['messages'][-1].content[:100]}...\")\n",
    "    print(f\"í˜„ì¬ ë‹¨ê³„: {result.get('current_phase', 'Unknown')}\")\n",
    "    print(f\"ê°ì • íŒíŠ¸: {result.get('emotion_hints', [])}\")\n",
    "    print(f\"ìƒí™© íŒíŠ¸: {result.get('situation_hints', [])}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê¸°ë³¸ ëŒ€í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë…¸ë“œ ì‹¤í–‰ ê³¼ì • í™•ì¸ (ASYNC) ===\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=Hello, I'm feeling stressed from work.\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Final merged hints - emotions: ['stressed'], situations: ['work stress']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['stressed']) or situation hints (['work stress']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: []\n",
      "DEBUG: Current situation hints in state: []\n",
      "DEBUG: Final emotion hints: ['stressed']\n",
      "DEBUG: Final situation hints: ['work stress']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"Hello, I'm feeling stressed from work.\"]\n",
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to END - phase: greeting, consent: False\n",
      "ìŠ¤í…: {'conversation_node': {'messages': [AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='1542d2c0-9eae-4236-be62-ff3f8ede709c')], 'emotion_hints': ['stressed'], 'situation_hints': ['work stress']}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê° ë…¸ë“œ ì‹¤í–‰ ê³¼ì • í™•ì¸ (ASYNC)\n",
    "print(\"=== ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë…¸ë“œ ì‹¤í–‰ ê³¼ì • í™•ì¸ (ASYNC) ===\")\n",
    "\n",
    "stream_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Hello, I'm feeling stressed from work.\")],\n",
    "    \"emotion_hints\": [],\n",
    "    \"situation_hints\": [],\n",
    "    \"current_phase\": \"greeting\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # ASYNC ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©\n",
    "    async for step in graph.astream(stream_state, config=config):\n",
    "        print(f\"ìŠ¤í…: {step}\")\n",
    "        print(\"---\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Art Curation íŠ¸ë¦¬ê±° ì¡°ê±´ í…ŒìŠ¤íŠ¸ (ASYNC) ===\n",
      "íë ˆì´ì…˜ ì¤€ë¹„ ìƒíƒœ:\n",
      "- current_phase: ready_for_curation\n",
      "- consent_for_reco: True\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "ì˜ˆìƒ ë¼ìš°íŒ…: art_curation_node\n",
      "\n",
      "íë ˆì´ì…˜ ì¤€ë¹„ ìƒíƒœë¡œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸...\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints', 'consent_for_reco']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=I'm really stressed and overwhelmed. Can you recommend some art for me?\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed', 'overwhelmed'], situations: []\n",
      "DEBUG: Final merged hints - emotions: ['stressed', 'overwhelmed', 'anxious'], situations: ['work pressure', 'academic stress']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['stressed', 'overwhelmed', 'anxious']) or situation hints (['work pressure', 'academic stress']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: ['stressed', 'overwhelmed', 'anxious']\n",
      "DEBUG: Current situation hints in state: ['work pressure', 'academic stress']\n",
      "DEBUG: Final emotion hints: ['stressed', 'overwhelmed', 'anxious']\n",
      "DEBUG: Final situation hints: ['work pressure', 'academic stress']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"I'm really stressed and overwhelmed. Can you recommend some art for me?\"]\n",
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "ìŠ¤í…: {'conversation_node': {'messages': [AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='2932066d-322d-4245-9a96-63721d2d216b')], 'emotion_hints': ['stressed', 'overwhelmed', 'anxious'], 'situation_hints': ['work pressure', 'academic stress']}}\n",
      "---\n",
      "WARNING: Store is None in art_curation_node, using InMemoryStore fallback\n",
      "DEBUG: Starting art curation node\n",
      "DEBUG: Loaded user memories: []\n",
      "DEBUG: conversation_state type: <class 'dict'>\n",
      "DEBUG: conversation_state content: {'messages': [HumanMessage(content=\"I'm really stressed and overwhelmed. Can you recommend some art for me?\", additional_kwargs={}, response_metadata={}, id='911c4d13-5ed0-40d8-94ce-d9515a512889'), AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='2932066d-322d-4245-9a96-63721d2d216b')], 'current_phase': 'ready_for_curation', 'emotion_hints': ['stressed', 'overwhelmed', 'anxious'], 'situation_hints': ['work pressure', 'academic stress'], 'consent_for_reco': True}\n",
      "DEBUG: Curation input prepared: {'situation': 'general emotional support and mood enhancement', 'emotions': ['stressed', 'overwhelmed', 'anxious'], 'preferences': None, 'confidence_level': 0.6000000000000001}\n",
      "DEBUG: Changed to art curation directory: /Users/ijunhyeong/Desktop/arti_llm/art_curation_engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:Setting up LangChain RAG components...\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading LangChain RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:âœ… Embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:art_curation_engine.core.langchain_rag_system:âœ… Text splitter configured\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:art_curation_engine.core.langchain_rag_system:âœ… Vector store loaded from langchain_vectorstore\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store\n",
      "âœ… LangChain RAG system loaded successfully\n",
      "âœ… LLM setup complete (OpenAI)\n",
      "ğŸ“š Extracting subject vocabulary from metadata...\n",
      "âœ… Extracted 353 unique subject terms\n",
      "ğŸ“Š Top 10 subjects: [('portraits', 261), ('portrait', 197), ('portraits: male subject', 103), ('man', 88), ('fashion', 85), ('portraits: female subject', 85), ('people', 76), ('woman', 63), ('century of progress', 60), (\"world's fairs\", 60)]\n",
      "âœ… Loaded 10 concept categories\n",
      "âœ… LLM setup complete for dynamic generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x34b14a350>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x34b14bd90>\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:LLM initialized successfully\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 60 cached scores\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 30 cached justifications\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Step 6 LLM Reranker initialized with model: accounts/fireworks/models/llama-v3p1-70b-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Could not load similarity model: PermissionError at /Volumes/X31 when downloading sentence-transformers/all-MiniLM-L6-v2. Check cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); 2) a previous download was canceled and the lock file needs manual removal.\n",
      "âœ… Dynamic Keyword/Prompt Generator initialized\n",
      "âœ… Dynamic keyword/prompt generator initialized\n",
      "ğŸ“š Loaded 298 artworks from metadata\n",
      "âœ… Stage A initialized with 298 artworks\n",
      "DEBUG: Starting Step 5 - RAG brief generation\n",
      "DEBUG: Starting Stage A - Candidate collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Generating session brief with dynamic LangChain RAG...\n",
      "   Situation: general emotional support and mood enhancement\n",
      "   Emotions: ['stressed', 'overwhelmed', 'anxious']\n",
      "âœ… Using cached result\n",
      "\n",
      "ğŸ­ Stage A: Candidate Collection (balanced mode)\n",
      "ğŸ“ Situation: general emotional support and mood enhancement\n",
      "ğŸ˜Š Emotions: ['stressed', 'overwhelmed', 'anxious']\n",
      "================================================================================\n",
      "ğŸ” A1: Metadata OR expansion (target: 200 candidates)\n",
      "ğŸ¯ Dynamic keyword/prompt generation...\n",
      "   Situation: general emotional support and mood enhancement...\n",
      "   Emotions: ['stressed', 'overwhelmed', 'anxious']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
      "INFO:root:Loaded built-in ViT-B-32 model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dynamic generation complete in 4.144s\n",
      "   Keywords: 10\n",
      "   Prompts: 3\n",
      "ğŸ”‘ Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "âœ… A1 complete: 200 candidates (from 294 matches)\n",
      "ğŸ¯ A2: CLIP textâ†’image search (per_query: 140, cap: 150)\n",
      "ğŸ”§ Loading CLIP model and FAISS index...\n",
      "= Attempting to load model from local cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Instantiating model architecture: CLIP\n",
      "INFO:root:Loading full pretrained weights from: /Users/ijunhyeong/.cache/huggingface/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/snapshots/1a25a446712ba5ee05982a381eed697ef9b435cf/open_clip_model.safetensors\n",
      "INFO:root:Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
      "INFO:root:Model ViT-B-32 creation process complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully from local cache\n",
      "âœ… FAISS index loaded with 298 embeddings\n",
      "ğŸ“¦ Dynamic generation cache hit in 0.000s\n",
      "ğŸ¨ Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, with ...\n",
      "   3. An abstract representation of anxiety, using swirling blue a...\n",
      "   ğŸ” Searching prompt 1/3: A serene landscape with a girl sitting by a calm body of wat...\n",
      "   ğŸ” Searching prompt 2/3: A portrait of a family enjoying a sunny day in a park, with ...\n",
      "   ğŸ” Searching prompt 3/3: An abstract representation of anxiety, using swirling blue a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.step6_llm_reranking:Starting Step 6 reranking: 3 â†’ 8 candidates\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Phase 1: Scoring candidates with LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/emotional_art_graph.py\", line 1511, in art_curation_node\n",
      "    final_recs = await loop.run_in_executor(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/arti_chatbot/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 259, in rerank_candidates\n",
      "    all_scores = self._score_all_candidates(rag_brief, candidates, brief_hash)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 306, in _score_all_candidates\n",
      "    artwork_id = candidate.get('artwork_id', candidate.get('id', ''))\n",
      "                 ^^^^^^^^^^^^^\n",
      "AttributeError: 'str' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… A2 complete: 150 candidates from 239 total matches\n",
      "ğŸ”— Merging A1 and A2 results (target: 150)\n",
      "âœ… Merge complete: 150 final candidates\n",
      "ğŸ“¦ Dynamic generation cache hit in 0.000s\n",
      "ğŸ”‘ Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "ğŸ“¦ Dynamic generation cache hit in 0.000s\n",
      "ğŸ¨ Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, with ...\n",
      "   3. An abstract representation of anxiety, using swirling blue a...\n",
      "\n",
      "ğŸ“Š Stage A Results (balanced):\n",
      "   Final candidates: 150\n",
      "   A1 metadata hits: 200\n",
      "   A2 CLIP hits: 150\n",
      "   Generated keywords: 10\n",
      "   CLIP prompts: 3\n",
      "\n",
      "ğŸ¯ Generating session brief with dynamic LangChain RAG...\n",
      "   Situation: general emotional support and mood enhancement\n",
      "   Emotions: ['overwhelmed', 'stressed', 'tired']\n",
      "âœ… Using cached result\n",
      "\n",
      "ğŸ­ Stage A: Candidate Collection (balanced mode)\n",
      "ğŸ“ Situation: general emotional support and mood enhancement\n",
      "ğŸ˜Š Emotions: ['overwhelmed', 'stressed', 'tired']\n",
      "================================================================================\n",
      "ğŸ” A1: Metadata OR expansion (target: 200 candidates)\n",
      "ğŸ¯ Dynamic keyword/prompt generation...\n",
      "   Situation: general emotional support and mood enhancement...\n",
      "   Emotions: ['overwhelmed', 'stressed', 'tired']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Starting Step 6 - LLM reranking\n",
      "DEBUG: Art curation error: 'str' object has no attribute 'get'\n",
      "DEBUG: Restored working directory to /Users/ijunhyeong/Desktop/arti_llm\n",
      "ìŠ¤í…: {'art_curation_node': {'messages': [AIMessage(content='I encountered an issue with the art database. Would you like to continue our conversation, and I can try the recommendations again later?', additional_kwargs={}, response_metadata={}, id='2cecc9d3-6f8d-442e-9f2c-a16c7fc9af32')], 'current_phase': 'continuing'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Art Curation íŠ¸ë¦¬ê±° ì¡°ê±´ í…ŒìŠ¤íŠ¸ (ASYNC)\n",
    "print(\"=== Art Curation íŠ¸ë¦¬ê±° ì¡°ê±´ í…ŒìŠ¤íŠ¸ (ASYNC) ===\")\n",
    "\n",
    "# ready_for_curation ìƒíƒœë¡œ ì„¤ì •\n",
    "curation_ready_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"I'm really stressed and overwhelmed. Can you recommend some art for me?\"),\n",
    "    ],\n",
    "    \"emotion_hints\": [\"stressed\", \"overwhelmed\", \"anxious\"],\n",
    "    \"situation_hints\": [\"work pressure\", \"academic stress\"],\n",
    "    \"current_phase\": \"ready_for_curation\",\n",
    "    \"consent_for_reco\": True\n",
    "}\n",
    "\n",
    "print(\"íë ˆì´ì…˜ ì¤€ë¹„ ìƒíƒœ:\")\n",
    "print(f\"- current_phase: {curation_ready_state.get('current_phase')}\")\n",
    "print(f\"- consent_for_reco: {curation_ready_state.get('consent_for_reco')}\")\n",
    "\n",
    "# should_curate_artë¡œ ë¼ìš°íŒ… í™•ì¸\n",
    "routing_result = should_curate_art(curation_ready_state)\n",
    "print(f\"ì˜ˆìƒ ë¼ìš°íŒ…: {routing_result}\")\n",
    "\n",
    "print(\"\\níë ˆì´ì…˜ ì¤€ë¹„ ìƒíƒœë¡œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸...\")\n",
    "try:\n",
    "    async for step in graph.astream(curation_ready_state, config=config):\n",
    "        print(f\"ìŠ¤í…: {step}\")\n",
    "        print(\"---\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ íë ˆì´ì…˜ íŠ¸ë¦¬ê±° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== prepare_curation_input í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ===\n",
      "DEBUG: conversation_state type: <class '__main__.FakeState'>\n",
      "DEBUG: conversation_state content: <__main__.FakeState object at 0x1745e0650>\n",
      "âœ… íë ˆì´ì…˜ ì…ë ¥ ìƒì„± ì„±ê³µ:\n",
      "- situation: academic stress from research work with underlying feeling overwhelmed\n",
      "- emotions: ['overwhelmed', 'stressed', 'tired', 'anxious']\n",
      "- preferences: {'liked_styles': ['minimalist', 'abstract'], 'avoided_themes': [], 'effective_colors': ['blue', 'green'], 'preferred_periods': []}\n",
      "- confidence_level: 1.0\n"
     ]
    }
   ],
   "source": [
    "# prepare_curation_input í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
    "from emotional_art_graph import prepare_curation_input\n",
    "\n",
    "print(\"=== prepare_curation_input í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ===\")\n",
    "\n",
    "# ê°€ì§œ ë©”ëª¨ë¦¬ ë°ì´í„°\n",
    "fake_memories = {\n",
    "    'user_profile': {\n",
    "        'current_situation': 'academic stress from research work',\n",
    "        'emotional_context': 'feeling overwhelmed',\n",
    "        'emotions': ['stressed', 'anxious', 'tired']\n",
    "    },\n",
    "    'art_preferences': {\n",
    "        'preferred_styles': ['minimalist', 'abstract'],\n",
    "        'effective_colors': ['blue', 'green']\n",
    "    }\n",
    "}\n",
    "\n",
    "# ê°€ì§œ state ë°ì´í„° (EmotionalArtStateì™€ ìœ ì‚¬í•˜ê²Œ)\n",
    "class FakeState:\n",
    "    def __init__(self, data):\n",
    "        self.emotion_hints = data.get('emotion_hints', [])\n",
    "        self.situation_hints = data.get('situation_hints', [])\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "\n",
    "fake_state = FakeState({\n",
    "    'emotion_hints': ['overwhelmed', 'stressed', 'tired'],\n",
    "    'situation_hints': ['academic pressure', 'research deadlines']\n",
    "})\n",
    "\n",
    "try:\n",
    "    curation_input = prepare_curation_input(fake_memories, fake_state)\n",
    "    print(f\"âœ… íë ˆì´ì…˜ ì…ë ¥ ìƒì„± ì„±ê³µ:\")\n",
    "    print(f\"- situation: {curation_input.get('situation')}\")\n",
    "    print(f\"- emotions: {curation_input.get('emotions')}\")\n",
    "    print(f\"- preferences: {curation_input.get('preferences')}\")\n",
    "    print(f\"- confidence_level: {curation_input.get('confidence_level')}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ prepare_curation_input í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:core.langchain_rag_system:Setting up LangChain RAG components...\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Art Curation Engine ì§ì ‘ í…ŒìŠ¤íŠ¸ ===\n",
      "âœ… ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: /Users/ijunhyeong/Desktop/arti_llm/art_curation_engine\n",
      "ğŸ”„ Loading LangChain RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:core.langchain_rag_system:âœ… Embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:core.langchain_rag_system:âœ… Text splitter configured\n",
      "INFO:core.langchain_rag_system:âœ… Vector store loaded from langchain_vectorstore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store\n",
      "âœ… LangChain RAG system loaded successfully\n",
      "âœ… LLM setup complete (OpenAI)\n",
      "âœ… RAGSessionBrief ë¡œë“œ ì„±ê³µ\n",
      "í…ŒìŠ¤íŠ¸ ì…ë ¥: situation='academic stress from research work', emotions=['overwhelmed', 'stressed', 'tired']\n",
      "\n",
      "ğŸ¯ Generating session brief with dynamic LangChain RAG...\n",
      "   Situation: academic stress from research work\n",
      "   Emotions: ['overwhelmed', 'stressed', 'tired']\n",
      "âœ… Using cached result\n",
      "âœ… RAG Brief ìƒì„± ì„±ê³µ: <class 'dict'>\n",
      "Brief keys: ['brief', 'evidence_used', 'queries_used', 'user_input', 'metadata']\n",
      "Brief ìƒ˜í”Œ:\n",
      "  brief: {'situation_analysis': 'The user is experiencing academic stress from research work, leading to feel...\n",
      "  evidence_used: [{'title': 'Color arousal and performance A comparis', 'year': 'Unknown', 'domain': 'Color Psycholog...\n",
      "  queries_used: ['color psychology effects on stress reduction in academic environments', 'environmental design stra...\n",
      "âœ… ì‘ì—… ë””ë ‰í† ë¦¬ ë³µì›: /Users/ijunhyeong/Desktop/arti_llm\n"
     ]
    }
   ],
   "source": [
    "# Art Curation Engine ì§ì ‘ í…ŒìŠ¤íŠ¸\n",
    "print(\"=== Art Curation Engine ì§ì ‘ í…ŒìŠ¤íŠ¸ ===\")\n",
    "\n",
    "# art_curation_engine ë””ë ‰í† ë¦¬ë¡œ ë³€ê²½\n",
    "import os\n",
    "original_cwd = os.getcwd()\n",
    "art_engine_path = '/Users/ijunhyeong/Desktop/arti_llm/art_curation_engine'\n",
    "\n",
    "if os.path.exists(art_engine_path):\n",
    "    os.chdir(art_engine_path)\n",
    "    print(f\"âœ… ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½: {art_engine_path}\")\n",
    "    \n",
    "    try:\n",
    "        from core import RAGSessionBrief\n",
    "        \n",
    "        rag_session = RAGSessionBrief()\n",
    "        print(\"âœ… RAGSessionBrief ë¡œë“œ ì„±ê³µ\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸\n",
    "        test_situation = \"academic stress from research work\"\n",
    "        test_emotions = [\"overwhelmed\", \"stressed\", \"tired\"]\n",
    "        \n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ì…ë ¥: situation='{test_situation}', emotions={test_emotions}\")\n",
    "        \n",
    "        brief = rag_session.generate_brief(test_situation, test_emotions)\n",
    "        print(f\"âœ… RAG Brief ìƒì„± ì„±ê³µ: {type(brief)}\")\n",
    "        print(f\"Brief keys: {list(brief.keys()) if isinstance(brief, dict) else 'Not a dict'}\")\n",
    "        \n",
    "        if isinstance(brief, dict):\n",
    "            print(f\"Brief ìƒ˜í”Œ:\")\n",
    "            for key, value in list(brief.items())[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥\n",
    "                print(f\"  {key}: {str(value)[:100]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Art Curation Engine í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        os.chdir(original_cwd)\n",
    "        print(f\"âœ… ì‘ì—… ë””ë ‰í† ë¦¬ ë³µì›: {original_cwd}\")\n",
    "else:\n",
    "    print(f\"âŒ Art Curation Engine ê²½ë¡œ ì—†ìŒ: {art_engine_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ (ASYNC) ===\n",
      "ì•„íŠ¸ íë ˆì´ì…˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸...\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "State: ['messages', 'current_phase', 'emotion_hints', 'situation_hints', 'consent_for_reco']\n",
      "=== NEW CONVERSATION_NODE STARTED ===\n",
      "WARNING: Store is None, using InMemoryStore fallback\n",
      "DEBUG: Phase=greeting, User message=I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\n",
      "DEBUG: Raw extracted hints - emotions: ['stressed', 'overwhelmed', 'tired'], situations: ['work stress', 'mental health', 'need for relaxation']\n",
      "DEBUG: Final merged hints - emotions: ['overwhelmed', 'stressed', 'tired'], situations: ['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation']\n",
      "DEBUG: Auto-triggered profile update due to hints\n",
      "DEBUG: Memory analysis={'update_needed': True, 'update_type': 'profile', 'reason': \"Emotion hints (['overwhelmed', 'stressed', 'tired']) or situation hints (['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation']) collected\"}\n",
      "DEBUG: Response=Hey there! I'm here to chat and maybe help you dis...\n",
      "DEBUG: Current emotion hints in state: ['overwhelmed', 'stressed', 'tired']\n",
      "DEBUG: Current situation hints in state: ['research work', 'academic pressure']\n",
      "DEBUG: Final emotion hints: ['overwhelmed', 'stressed', 'tired']\n",
      "DEBUG: Final situation hints: ['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation']\n",
      "DEBUG: All state updates: ['emotion_hints', 'situation_hints']\n",
      "DEBUG: About to update profile memory\n",
      "DEBUG: Recent messages for extraction: [\"I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:Setting up LangChain RAG components...\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Memory updated successfully: profile - 1 items\n",
      "DEBUG: Routing to art curation - phase: ready_for_curation, consent: True\n",
      "WARNING: Store is None in art_curation_node, using InMemoryStore fallback\n",
      "DEBUG: Starting art curation node\n",
      "DEBUG: Loaded user memories: []\n",
      "DEBUG: conversation_state type: <class 'dict'>\n",
      "DEBUG: conversation_state content: {'messages': [HumanMessage(content=\"I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\", additional_kwargs={}, response_metadata={}, id='88c8132d-e9df-458c-8393-b15c2d3c4c4d'), AIMessage(content=\"Hey there! I'm here to chat and maybe help you discover some amazing art along the way. How's your day going?\", additional_kwargs={}, response_metadata={}, id='ca87ce68-fb9e-488a-aa92-2a480f9a1ad1')], 'current_phase': 'ready_for_curation', 'emotion_hints': ['overwhelmed', 'stressed', 'tired'], 'situation_hints': ['research work', 'academic pressure', 'work stress', 'mental health', 'need for relaxation'], 'consent_for_reco': True}\n",
      "DEBUG: Curation input prepared: {'situation': 'general emotional support and mood enhancement', 'emotions': ['overwhelmed', 'stressed', 'tired'], 'preferences': None, 'confidence_level': 0.6000000000000001}\n",
      "DEBUG: Changed to art curation directory: /Users/ijunhyeong/Desktop/arti_llm/art_curation_engine\n",
      "ğŸ”„ Loading LangChain RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:art_curation_engine.core.langchain_rag_system:âœ… Embeddings model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:art_curation_engine.core.langchain_rag_system:âœ… Text splitter configured\n",
      "INFO:art_curation_engine.core.langchain_rag_system:âœ… Vector store loaded from langchain_vectorstore\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store\n",
      "âœ… LangChain RAG system loaded successfully\n",
      "âœ… LLM setup complete (OpenAI)\n",
      "ğŸ“š Extracting subject vocabulary from metadata...\n",
      "âœ… Extracted 353 unique subject terms\n",
      "ğŸ“Š Top 10 subjects: [('portraits', 261), ('portrait', 197), ('portraits: male subject', 103), ('man', 88), ('fashion', 85), ('portraits: female subject', 85), ('people', 76), ('woman', 63), ('century of progress', 60), (\"world's fairs\", 60)]\n",
      "âœ… Loaded 10 concept categories\n",
      "âœ… LLM setup complete for dynamic generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Volumes/X31'\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x321c61e50>\n",
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x321c63450>\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:LLM initialized successfully\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 60 cached scores\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Loaded 30 cached justifications\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Step 6 LLM Reranker initialized with model: accounts/fireworks/models/llama-v3p1-70b-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Could not load similarity model: PermissionError at /Volumes/X31 when downloading sentence-transformers/all-MiniLM-L6-v2. Check cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); 2) a previous download was canceled and the lock file needs manual removal.\n",
      "âœ… Dynamic Keyword/Prompt Generator initialized\n",
      "âœ… Dynamic keyword/prompt generator initialized\n",
      "ğŸ“š Loaded 298 artworks from metadata\n",
      "âœ… Stage A initialized with 298 artworks\n",
      "DEBUG: Starting Step 5 - RAG brief generation\n",
      "DEBUG: Starting Stage A - Candidate collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
      "INFO:root:Loaded built-in ViT-B-32 model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dynamic generation complete in 3.681s\n",
      "   Keywords: 10\n",
      "   Prompts: 3\n",
      "ğŸ”‘ Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "âœ… A1 complete: 200 candidates (from 294 matches)\n",
      "ğŸ¯ A2: CLIP textâ†’image search (per_query: 140, cap: 150)\n",
      "ğŸ”§ Loading CLIP model and FAISS index...\n",
      "= Attempting to load model from local cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Instantiating model architecture: CLIP\n",
      "INFO:root:Loading full pretrained weights from: /Users/ijunhyeong/.cache/huggingface/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/snapshots/1a25a446712ba5ee05982a381eed697ef9b435cf/open_clip_model.safetensors\n",
      "INFO:root:Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
      "INFO:root:Model ViT-B-32 creation process complete.\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Starting Step 6 reranking: 3 â†’ 8 candidates\n",
      "INFO:art_curation_engine.core.step6_llm_reranking:Phase 1: Scoring candidates with LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/emotional_art_graph.py\", line 1511, in art_curation_node\n",
      "    final_recs = await loop.run_in_executor(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/arti_chatbot/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 259, in rerank_candidates\n",
      "    all_scores = self._score_all_candidates(rag_brief, candidates, brief_hash)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ijunhyeong/Desktop/arti_llm/studio/art_curation_engine/core/step6_llm_reranking.py\", line 306, in _score_all_candidates\n",
      "    artwork_id = candidate.get('artwork_id', candidate.get('id', ''))\n",
      "                 ^^^^^^^^^^^^^\n",
      "AttributeError: 'str' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully from local cache\n",
      "âœ… FAISS index loaded with 298 embeddings\n",
      "ğŸ“¦ Dynamic generation cache hit in 0.000s\n",
      "ğŸ¨ Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, weari...\n",
      "   3. An abstract representation of tiredness, using swirling blue...\n",
      "   ğŸ” Searching prompt 1/3: A serene landscape with a girl sitting by a calm body of wat...\n",
      "   ğŸ” Searching prompt 2/3: A portrait of a family enjoying a sunny day in a park, weari...\n",
      "   ğŸ” Searching prompt 3/3: An abstract representation of tiredness, using swirling blue...\n",
      "âœ… A2 complete: 150 candidates from 235 total matches\n",
      "ğŸ”— Merging A1 and A2 results (target: 150)\n",
      "âœ… Merge complete: 150 final candidates\n",
      "ğŸ“¦ Dynamic generation cache hit in 0.000s\n",
      "ğŸ”‘ Generated 10 open keywords: ['lake', 'girl', 'mountains', 'water', 'landscape', 'trees', 'blue', 'portraits', 'hat', 'ocean']\n",
      "ğŸ“¦ Dynamic generation cache hit in 0.000s\n",
      "ğŸ¨ Generated 3 CLIP prompts:\n",
      "   1. A serene landscape with a girl sitting by a calm body of wat...\n",
      "   2. A portrait of a family enjoying a sunny day in a park, weari...\n",
      "   3. An abstract representation of tiredness, using swirling blue...\n",
      "\n",
      "ğŸ“Š Stage A Results (balanced):\n",
      "   Final candidates: 150\n",
      "   A1 metadata hits: 200\n",
      "   A2 CLIP hits: 150\n",
      "   Generated keywords: 10\n",
      "   CLIP prompts: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Starting Step 6 - LLM reranking\n",
      "DEBUG: Art curation error: 'str' object has no attribute 'get'\n",
      "DEBUG: Restored working directory to /Users/ijunhyeong/Desktop/arti_llm\n",
      "âœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì„±ê³µ\n",
      "ë§ˆì§€ë§‰ ë©”ì‹œì§€: I encountered an issue with the art database. Would you like to continue our conversation, and I can try the recommendations again later?...\n",
      "í˜„ì¬ ë‹¨ê³„: continuing\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ - art_curation_nodeê¹Œì§€ ì‹¤í–‰ (ASYNC)\n",
    "print(\"=== ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ (ASYNC) ===\")\n",
    "\n",
    "# Art curationì„ íŠ¸ë¦¬ê±°í•˜ëŠ” ìƒíƒœ\n",
    "full_test_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"I'm really struggling with stress from my research work. I feel overwhelmed and tired. Can you help me find some art that might make me feel better?\")\n",
    "    ],\n",
    "    \"emotion_hints\": [\"overwhelmed\", \"stressed\", \"tired\"],\n",
    "    \"situation_hints\": [\"research work\", \"academic pressure\"],\n",
    "    \"current_phase\": \"ready_for_curation\",\n",
    "    \"consent_for_reco\": True\n",
    "}\n",
    "\n",
    "print(\"ì•„íŠ¸ íë ˆì´ì…˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸...\")\n",
    "try:\n",
    "    result = await graph.ainvoke(full_test_state, config=config)\n",
    "    print(f\"âœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì„±ê³µ\")\n",
    "    print(f\"ë§ˆì§€ë§‰ ë©”ì‹œì§€: {result['messages'][-1].content[:200]}...\")\n",
    "    print(f\"í˜„ì¬ ë‹¨ê³„: {result.get('current_phase', 'Unknown')}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arti_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
